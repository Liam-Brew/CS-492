# Input and Output

## Table of Contents

- [Input and Output](#input-and-output)
  - [Table of Contents](#table-of-contents)
  - [I/O Hierarchy](#io-hierarchy)
  - [Programmed I/O](#programmed-io)
    - [Polling](#polling)
    - [Interrupts](#interrupts)
    - [Direct Memory Access (DMA)](#direct-memory-access-dma)
    - [Polling vs. Interrupts](#polling-vs-interrupts)
  - [Data Buffering and Caching](#data-buffering-and-caching)
    - [Using a Single Buffer](#using-a-single-buffer)
    - [Buffer Swapping](#buffer-swapping)
    - [Circular Buffer](#circular-buffer)
    - [Disk Block Caching](#disk-block-caching)
  - [Disk Scheduling](#disk-scheduling)
    - [Magnetic Disk Organization](#magnetic-disk-organization)
    - [Disk Access Optimization](#disk-access-optimization)
    - [SSTF Scheduling Algorithm](#sstf-scheduling-algorithm)
    - [Scan and C-Scan Scheduling Algorithms](#scan-and-c-scan-scheduling-algorithms)
  - [Error Handling](#error-handling)
    - [Error Detection and Correction](#error-detection-and-correction)
    - [Bad Block Detection and Handling](#bad-block-detection-and-handling)
    - [Stable Storage](#stable-storage)
    - [RAID](#raid)

## I/O Hierarchy

**Device controller/adapter**: electronic circuit capable of operating a specific I/O device using binary signals, interfaces through a set of hardware registers and flags

**Device driver**: device-specific program that implements I/O operations through the device controller that can be requested by both user applications or the OS

Components supplied along with a new device must include both a new controller and a new driver. I/O systems typically support incorporating the following new devices without modifying the OS:

- block-oriented devices (disks)
- character-oriented devices (keyboards, printers)
- network devices (modems, ethernet adapters)

## Programmed I/O

**Programmed I/O**: the CPU runs the device driver and performs the copying of all data between the I/O device controller and main memory. Programmed I/O can be implemented in several ways:

### Polling

**Polling**: technique to determine whether a device is busy or idly by reading a flag set and reset by the device controller

![polling](/notes/assets/io/polling.PNG)

### Interrupts

When interrupts are used for I/O processing, the controller interface remains the same, but the controller is equipped with the ability to issue interrupts to the CPU. The operand and opcode registers are used to describe and start an I/O operation. The status register indicates the success or failure of the last operation. The controller buffer holds the data transferred to or from the device

Under this approach, the driver blocks itself to await the completion of the I/O operation. The CPU is free to serve other processes in the meantime

![interrupts](/notes/assets/io/interrupts.PNG)

### Direct Memory Access (DMA)

**Direct memory access (DMA)**: uses a hardware controller to allow devices to access main memory directly without the involvement of the CPU. Under this approach the CPU only initiates a data transfer. The process executing the device driver then blocks itself, which frees the CPU to serve other processes in the meantime

![dma](/notes/assets/io/dma.PNG)

### Polling vs. Interrupts

Both polling and interrupts both result in overhead during I/O processes, but the sources of overhead are different. Therefore each is best fit for a certain scenario:

- **polling**: good choice in dedicated systems, where only a single process is running. Also suitable for devices that complete an I/O operation within a few microseconds (e.g. SSDs)
- **interrupts**: better for general purpose multi-process environments. Blocking and reactivating processes represents constant predictable overhead for each I/O operation

![pol_vs_int](/notes/assets/io/pol_vs_int.PNG)

## Data Buffering and Caching

**Buffer**: register or an area of main memory used to hold data generated by a producer process and removed at a later time by a consumer process. The buffer in a device controller decouples the device from the device driver, and the buffer in main memory decouples the device driver from the application

There are several ways to use buffers:

### Using a Single Buffer

The main purpose of using a single buffer is to decouple the producer from the consumer in time. The producer can generate a data item without the consumer being active simultaneously. Similarly, the consumer can copy the item from the buffer without the producer being active simultaneously

**Raw input mode** is when the driver passes all characters to the application unchanged. **Cooked input mode** is the driver modifies the buffer before passing it, such as waiting for full lines to be accumulated

![cooked_vs_raw](/notes/assets/io/cooked_vs_raw.PNG)

### Buffer Swapping

**Buffer swapping**: technique that allows the operations of a producer process and a consumer process to overlap by using two buffers. While buffer 1 is being filled, the consumer is copying buffer 2. When both processes terminate the two buffers are swapped

![cooked_vs_raw](/notes/assets/io/cooked_vs_raw.PNG)

### Circular Buffer

**Circular buffer**: fixed array of buffer slots filled by the producer and emptied by the consumer one slot at a time in ascending order, modulo the buffer size

### Disk Block Caching

**Disk block cache**: set of main memory buffers that contain the most recently accessed disk blocks. All blocks are divided into categories that are linked together via separate linked lists. These categories are:

- **blocks critical to performance** (e.g. those used internally by the OS): must remain resident at all times and are kept on a locked linked list
- **blocks expected to be accessed in the near future** (e.g. those holding data from regular user files): list implements the LRU policy. Blocks are moved to the rear of the list when accessed, with those at the front being removed when no free buffers are available
- **blocks expected to be accessed only once or infrequently** (e.g. blocks containing file control blocks): added to the front of the same LRU list and are thus removed quickly

## Disk Scheduling

### Magnetic Disk Organization

Disks are the most common mass storage devices. Elements of a disk are:

- **track**: one of the many concentric rings on a magnetic disk. Data is accessed via a read/write head mounted on a movable arm
- **sector**: portion of a track and is the smallest unit of data that can be read or written with a single r/w operation

The time to access data on a disk consists of three components:

- **seek time**: time to move the r/w head from the current position to the track containing the data. This time is proportional to the distance the r/w head needs to traverse
- **rotational delay (rotational latency)**: time to wait for the desired data item to pass under the r/w head. This delay is one half of the time of one disk revolution on average, and therefore depends on the disk's rotational speed
- **data transfer time**: time to transfer the desired number of bits to or from the disk, and is directly proportional to the disk's rotational speed

Data is moved throughout the disk at two rates:

- **peak transfer rate**: rate at which the data is streamed to or from the disk once the read/write head is at the beginning of the sector to be transferred. This depends on the rotational speed of the disk and the number of sectors per track
- **sustained data rate**: rate at which the disk can transfer data continuously. This includes the seek times over multiple tracks and other overhead in accessing the data over time

![disk_organization](/notes/assets/io/disk_organization.PNG)

### Disk Access Optimization

The seek time and the rotational delay involve mechanical motion of the r/w head and the physical disk rotation. Both times are in the millisecond range and thus constitute most of the access time to a disk block. While the rotational delay is easy to optimize, the seek time is more difficult as the r/w head sweeps back and forth across different tracks. There are several different algorithms to optimize this:

### SSTF Scheduling Algorithm

**Shortest seek time first (SSTF)**: considers the list of all pending requests and always selects the request that requires the shortest travel distance from the current position

The algorithm minimizes the travel distance of the r/w head and thus maximizes the disk's performance but the main drawback is a lack of fairness in treating the different requests

Starvation is possible under SSTF. SSTF moves the r/w to the closest possible track. When an unbounded stream of requests for tracks in the current vicinity is arriving, then the servicing of more distant tracks could be postponed indefinitely

### Scan and C-Scan Scheduling Algorithms

**Scan scheduling**: the r/w head maintains a current direction of travel and services all request sequentially in the current direction. When the outermost request is reached, the direction is reversed and the algorithm services all requests in the opposite direction

The performance of this algorithm is less than SSTF, however starvation is not an issue as each request is guaranteed to be served within one sweep of the r/w head. However, this means that access time to different tracks is not uniform

**C-Scan scheduling**: variant of the Scan algorithm that services requests in only one direction. When the outermost request is reached, the r/w head sweeps back to the opposite end of the disk and starts servicing requests again in the same direction.

Unlike Scan, C-Scan guarantees a uniform access time to all tracks, because the r/w head services all requests in only ascending order. Thus a position in the midrange of the disk conveys no advantage over any other position

![scan_vs_cscan](/notes/assets/io/scan_vs_cscan.PNG)

## Error Handling

### Error Detection and Correction

Data on a disk can become inconsistent for two reasons:

- a system crash during a write operation can leave a disk block in a partially updated state
- a spontaneously occurring bad block, caused by aging or physical damage to the recording medium, makes the reading or re-writing of the block impossible

**Parity bit**: bit added to a string of bits to ensure that the total number of 1's in the string is even or odd. These are used to detect a single erroneous bit in a string

**Error correcting code (ECC)**: includes multiple parity bits in a string to permit the detection and automatic correction of some number of erroneous bits

A popular ECC is the Hamming code, which is used to correct a single bit error. This encoding inserts even parity bits into a string of arbitrary length at positions 1, 2, 4, 8, ..., $2^i$

- parity bit p1 covers all positions that have a 1 in the least significant bit: 1, 3, 5, 7, ...
- parity bit p2 covers all positions that have a 1 in the second least significant bit: 2, 3, 6, 7, ...
- parity bit p4 covers all positions that have a 1 in the third significant bit: 4, 5, 6, 7, ... , etc.

### Bad Block Detection and Handling

**Bad block (bad sector)**: storage block that is no longer reliable for storing and retrieving data due to physical damage. ECCs are associated with each block to detect and correct some number of corrupted bits within it

To maintain the logical sequence of blocks b\[0]...b\[D-1] without gaps, the disk provides some number of spare sectors on each track. The damaged block, b\[i], can be remapped to a spare sector in one of two ways:

- **sector forwarding**: bad block b\[i] is mapped to one of the spare sectors. This is a fast solution but the drawback is that logical blocks are no longer mapped to consecutive sectors, resulting in additional disk revolutions
- **sector slipping**: technique where all blocks following a bad block b\[i] are shifted right. The last block is mapped to a spare sector and b\[i] is mapped to the sector previously occupied by block b\[i+1]. This requires more work initially but maintains the sequential order of blocks

### Stable Storage

**Stable storage**: approach to data management that uses redundancy and a strict protocol for reading, writing, and error recovery to guarantee that all data is consistent in spite of media and crash failures

- **stable read**: guarantees to return a valid copy of any block
- **stable write**: guarantees that every block is updated atomically

### RAID

**Redundant Array of Independent Disks (RAID)**: set of disks viewed by the OS as a single mass storage device. This uses redundancy to decrease the probability of data loss. Several classes of RAIDs exist distinguished by amount, type, and location of the redundant data provided:

- **amount** of data can range from a single parity bit per block to a full duplication of the entire block
- **type** of data determines how many bit-errors can be detected and/or automatically corrected
- **location** of the data either segregated on separate disk units or distributed throughout all disk units

![raid](/notes/assets/io/raid.PNG)

**Striping**: technique where a sequence of data blocks, b\[i], is distributed over n disks such that disk\[i] contains block b\[i] modulo n. Striping is a technique to improve the performance of a RAID
